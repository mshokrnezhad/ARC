{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of interacting with Ollama/Llama3.2 via the `/api/chat` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: 5\n"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "import json  \n",
    "\n",
    "# **Configuration Variables**  \n",
    "PUBLIC_IP = \"86.50.229.229\"  \n",
    "PORT = 11434\n",
    "ENDPOINT = \"/api/chat\"  \n",
    "API_URL = f\"http://{PUBLIC_IP}:{PORT}{ENDPOINT}\"  \n",
    "\n",
    "# **Define Prompts and Context**  \n",
    "system_prompt_2 = \"You are an specialist that helps with {context}.\"  \n",
    "user_prompt = \"Can you answer the following question? {question} Just return the number without extra text.\"  \n",
    "\n",
    "context = \"algebra\"  \n",
    "question = \"What is the square root of 25?\"  \n",
    "\n",
    "# **Construct the Messages Payload**  \n",
    "messages = [  \n",
    "    {\"content\": system_prompt_2.format(context=context), \"role\": \"system\"},  \n",
    "    {\"content\": user_prompt.format(question=question), \"role\": \"user\"}  \n",
    "]  \n",
    "\n",
    "# **Prepare the Request Payload**  \n",
    "payload = {  \n",
    "    \"messages\": messages,  \n",
    "    \"model\": \"llama3.2\",\n",
    "    \"stream\": False  \n",
    "}  \n",
    "\n",
    "# **Send the POST Request**  \n",
    "try:  \n",
    "    response = requests.post(API_URL, data=json.dumps(payload))  \n",
    "    \n",
    "    if response.status_code == 200:  \n",
    "        response_data = response.json()  \n",
    "        reply = response_data.get(\"message\", []).get(\"content\", \"\")  \n",
    "        print(\"LLM Response:\", reply)  \n",
    "    else:  \n",
    "        print(f\"Request failed with status code {response.status_code}: {response.text}\")  \n",
    "\n",
    "except requests.exceptions.RequestException as e:  \n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of interacting with Ollama/Llama3.2 via the `/api/generate` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: The sky appears blue because of a phenomenon called Rayleigh scattering, named after British physicist Lord Rayleigh\n"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "import json  \n",
    "\n",
    "# **Configuration Variables**  \n",
    "PUBLIC_IP = \"86.50.229.229\"  \n",
    "PORT = 11434\n",
    "ENDPOINT = \"/api/generate\"  \n",
    "API_URL = f\"http://{PUBLIC_IP}:{PORT}{ENDPOINT}\"  \n",
    "\n",
    "# **Construct the Messages Payload**  \n",
    "prompt = \"Why is the sky blue? Explain at most in 100 words. \"\n",
    "\n",
    "# **Prepare the Request Payload**  \n",
    "payload = {  \n",
    "    \"model\": \"llama3.2\",\n",
    "    \"prompt\": prompt,\n",
    "    \"stream\": False, \n",
    "    \"options\": {\"num_predict\": 20}\n",
    "}  \n",
    "\n",
    "# **Send the POST Request**  \n",
    "try:  \n",
    "    response = requests.post(API_URL, data=json.dumps(payload))  \n",
    "    \n",
    "    if response.status_code == 200:  \n",
    "        response_data = response.json()  \n",
    "        reply = response_data.get(\"response\", [])\n",
    "        print(\"LLM Response:\", reply)  \n",
    "    else:  \n",
    "        print(f\"Request failed with status code {response.status_code}: {response.text}\")  \n",
    "\n",
    "except requests.exceptions.RequestException as e:  \n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
